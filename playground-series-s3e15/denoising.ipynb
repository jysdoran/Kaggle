{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/.pyenv/versions/3.7.16/envs/kaggle3.7/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>geometry</th>\n",
       "      <th>pressure [MPa]</th>\n",
       "      <th>mass_flux [kg/m2-s]</th>\n",
       "      <th>x_e_out [-]</th>\n",
       "      <th>D_e [mm]</th>\n",
       "      <th>D_h [mm]</th>\n",
       "      <th>length [mm]</th>\n",
       "      <th>chf_exp [MW/m2]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>0.1754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.8</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6049.0</td>\n",
       "      <td>-0.0416</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>762.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thompson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.79</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beus</td>\n",
       "      <td>annulus</td>\n",
       "      <td>13.79</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>-0.0279</td>\n",
       "      <td>5.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tube</td>\n",
       "      <td>13.79</td>\n",
       "      <td>686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author geometry  pressure [MPa]  mass_flux [kg/m2-s]  x_e_out [-]  \\\n",
       "id                                                                        \n",
       "0   Thompson     tube            7.00               3770.0       0.1754   \n",
       "1   Thompson     tube             NaN               6049.0      -0.0416   \n",
       "2   Thompson      NaN           13.79               2034.0       0.0335   \n",
       "3       Beus  annulus           13.79               3679.0      -0.0279   \n",
       "4        NaN     tube           13.79                686.0          NaN   \n",
       "\n",
       "    D_e [mm]  D_h [mm]  length [mm]  chf_exp [MW/m2]  \n",
       "id                                                    \n",
       "0        NaN      10.8        432.0              3.6  \n",
       "1       10.3      10.3        762.0              6.2  \n",
       "2        7.7       7.7        457.0              2.5  \n",
       "3        5.6      15.2       2134.0              3.0  \n",
       "4       11.1      11.1        457.0              2.8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = pd.read_csv(\"data.csv\", index_col=0)\n",
    "\n",
    "# split into train and test\n",
    "test_size = 4000\n",
    "df_train = df_0.iloc[:-2*test_size]\n",
    "df_dev = df_0.iloc[-2*test_size:-test_size]\n",
    "df_test = df_0.iloc[-test_size:]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pressure [MPa]</th>\n",
       "      <th>mass_flux [kg/m2-s]</th>\n",
       "      <th>x_e_out [-]</th>\n",
       "      <th>D_e [mm]</th>\n",
       "      <th>D_h [mm]</th>\n",
       "      <th>length [mm]</th>\n",
       "      <th>chf_exp [MW/m2]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20330.000000</td>\n",
       "      <td>20070.000000</td>\n",
       "      <td>15845.000000</td>\n",
       "      <td>19574.000000</td>\n",
       "      <td>20265.000000</td>\n",
       "      <td>20123.000000</td>\n",
       "      <td>23644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.628599</td>\n",
       "      <td>3060.824564</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>8.621105</td>\n",
       "      <td>14.142832</td>\n",
       "      <td>829.462605</td>\n",
       "      <td>3.791740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.334998</td>\n",
       "      <td>1778.014723</td>\n",
       "      <td>0.100673</td>\n",
       "      <td>5.161892</td>\n",
       "      <td>19.849561</td>\n",
       "      <td>671.040953</td>\n",
       "      <td>1.970519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.866700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.890000</td>\n",
       "      <td>1505.000000</td>\n",
       "      <td>-0.046500</td>\n",
       "      <td>4.775000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.790000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>914.000000</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.680000</td>\n",
       "      <td>7975.000000</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>19.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pressure [MPa]  mass_flux [kg/m2-s]   x_e_out [-]      D_e [mm]  \\\n",
       "count    20330.000000         20070.000000  15845.000000  19574.000000   \n",
       "mean        10.628599          3060.824564      0.000006      8.621105   \n",
       "std          4.334998          1778.014723      0.100673      5.161892   \n",
       "min          0.100000             0.000000     -0.866700      1.000000   \n",
       "25%          6.890000          1505.000000     -0.046500      4.775000   \n",
       "50%         11.030000          2730.000000      0.004900      7.800000   \n",
       "75%         13.790000          4069.000000      0.064900     10.800000   \n",
       "max         20.680000          7975.000000      0.232000     37.500000   \n",
       "\n",
       "           D_h [mm]   length [mm]  chf_exp [MW/m2]  \n",
       "count  20265.000000  20123.000000     23644.000000  \n",
       "mean      14.142832    829.462605         3.791740  \n",
       "std       19.849561    671.040953         1.970519  \n",
       "min        1.000000     10.000000         0.800000  \n",
       "25%        5.600000    318.000000         2.400000  \n",
       "50%       10.000000    610.000000         3.400000  \n",
       "75%       11.500000    914.000000         4.600000  \n",
       "max      120.000000   3048.000000        19.300000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask of missing data\n",
    "# mask = df_0.isnull()\n",
    "# mask.head()\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4069.0    712\n",
       "1356.0    485\n",
       "1519.0    474\n",
       "2034.0    387\n",
       "1000.0    314\n",
       "         ... \n",
       "3567.0      1\n",
       "5871.0      1\n",
       "791.0       1\n",
       "881.0       1\n",
       "849.0       1\n",
       "Name: mass_flux [kg/m2-s], Length: 701, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"mass_flux [kg/m2-s]\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annulus</th>\n",
       "      <th>plate</th>\n",
       "      <th>tube</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    annulus  plate  tube\n",
       "id                      \n",
       "0       0.0    0.0   1.0\n",
       "1       0.0    0.0   1.0\n",
       "2       NaN    NaN   NaN\n",
       "3       1.0    0.0   0.0\n",
       "4       0.0    0.0   1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.get_dummies(df_train[\"geometry\"]).head().copy()\n",
    "df1[df_train[\"geometry\"].head().isnull()] = np.nan\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='pressure [MPa]', ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use seaborn to plot the histograms for each column individually and stack them\n",
    "# sns.histplot(df_train, x=\"geometry\", hue=\"geometry\", multiple=\"stack\")\n",
    "# sns.histplot(df_train, x=\"author\", hue=\"author\", multiple=\"stack\")\n",
    "sns.histplot(df_train, x=\"pressure [MPa]\", multiple=\"stack\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskingDataset(Dataset):\n",
    "    def __init__(self, df, p_mask=0.2, categorical_cols=None):\n",
    "        self.features = len(df.columns)\n",
    "        self.p_mask = p_mask\n",
    "\n",
    "        self._categorical_cols = []\n",
    "        if categorical_cols is not None:\n",
    "            for col in categorical_cols:\n",
    "                one_hot = pd.get_dummies(df[col])\n",
    "                one_hot[df[col].isnull()] = np.nan\n",
    "\n",
    "                self._categorical_cols.append(one_hot.columns)\n",
    "                df = df.drop(col, axis=1)\n",
    "                df = pd.concat([df, one_hot], axis=1)\n",
    "\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def onehot_categorical_mask(self, column_mask):\n",
    "        return np.concatenate(\n",
    "            [np.full(len(cs), m) for m, cs in zip(column_mask, self._categorical_cols)]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.df.iloc[idx]\n",
    "        output_mask = torch.tensor(~record.isnull().values)\n",
    "\n",
    "        input_mask = ~np.random.binomial(1, self.p_mask, size=self.features).astype(\n",
    "            bool\n",
    "        )\n",
    "\n",
    "        # mask continuous columns normally\n",
    "        # mask categorical columns with all their columns\n",
    "\n",
    "        full_input_mask = (\n",
    "            torch.tensor(\n",
    "                np.concatenate(\n",
    "                    [\n",
    "                        input_mask[: -len(self._categorical_cols)],\n",
    "                        self.onehot_categorical_mask(\n",
    "                            input_mask[-len(self._categorical_cols) :]\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            & output_mask\n",
    "        )\n",
    "\n",
    "        x_in = record.values.copy()\n",
    "        x_in[~full_input_mask] = 0\n",
    "\n",
    "        x_out = record.values.copy()\n",
    "        x_out[~output_mask] = np.nan\n",
    "\n",
    "        # x = torch.tensor(record.values)\n",
    "        # return masked_tensor(x, full_input_mask), masked_tensor(x, output_mask)\n",
    "        return (\n",
    "            torch.as_tensor(x_in, dtype=torch.float32),\n",
    "            torch.as_tensor(x_out, dtype=torch.float32),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class FFModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x0):\n",
    "        x = self.activation(self.fc1(x0))\n",
    "        x = self.activation(self.fc2(x))\n",
    "\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "def separate_slices(categorical_slices, output_size):\n",
    "    slices = []\n",
    "    slice_is_categorical = []\n",
    "    prev_start = 0\n",
    "    for start, end in categorical_slices:\n",
    "        if start != prev_start:\n",
    "            slices.append(slice(prev_start, start))\n",
    "            slice_is_categorical.append(False)\n",
    "        slices.append(slice(start, end))\n",
    "        slice_is_categorical.append(True)\n",
    "        prev_start = end\n",
    "\n",
    "    if prev_start != output_size:\n",
    "        slices.append(slice(prev_start, output_size))\n",
    "        slice_is_categorical.append(False)\n",
    "\n",
    "    return slices, slice_is_categorical\n",
    "\n",
    "\n",
    "class MixedContCatModel(nn.Module):\n",
    "    def __init__(self, model, categorical_slices, output_size) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.slices, self.slice_is_categorical = separate_slices(\n",
    "            categorical_slices, output_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        for slice_, is_categorical in zip(self.slices, self.slice_is_categorical):\n",
    "            if is_categorical:\n",
    "                x[:, slice_] = self.softmax(x[:, slice_])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContCatLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        categorical_slices,\n",
    "        output_size,\n",
    "        cont_loss=nn.MSELoss(),\n",
    "        cat_loss=nn.CrossEntropyLoss(),\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_cats = len(categorical_slices)\n",
    "        slices, slice_is_categorical = separate_slices(categorical_slices, output_size)\n",
    "        self.cont_slices = [s for s, is_cat in zip(slices, slice_is_categorical) if not is_cat]\n",
    "        self.cat_slices = [s for s, is_cat in zip(slices, slice_is_categorical) if is_cat]\n",
    "\n",
    "        self.cont_loss = cont_loss\n",
    "        self.cat_loss = cat_loss\n",
    "\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        output_mask = ~torch.isnan(y_true)\n",
    "        y_pred = y_pred * output_mask\n",
    "        y_true = y_true.where(output_mask, torch.tensor(0.0))\n",
    "\n",
    "        y_pred_cont = torch.concat([y_pred[:, s] for s in self.cont_slices], dim=1)\n",
    "        y_true_cont = torch.concat([y_true[:, s] for s in self.cont_slices], dim=1)\n",
    "        loss_cont = self.cont_loss(y_pred_cont, y_true_cont)\n",
    "\n",
    "        losses_cat = []\n",
    "        for s in self.cat_slices:\n",
    "            y_pred_cat = y_pred[:, s]\n",
    "            y_true_cat = y_true[:, s]\n",
    "            losses_cat.append(self.cat_loss(y_pred_cat, y_true_cat))\n",
    "        \n",
    "        \n",
    "        return loss_cont, losses_cat\n",
    "\n",
    "class MixedContCatLoss(nn.Module):\n",
    "    def __init__(self, contcatloss, ratio):\n",
    "        super().__init__()\n",
    "\n",
    "        self.contcatloss = contcatloss\n",
    "        self.ratio = ratio\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss_cont, losses_cat = self.contcatloss(y_pred, y_true)\n",
    "\n",
    "        loss_cat = sum(losses_cat)\n",
    "\n",
    "        return self.ratio * loss_cont + (1 - self.ratio) * loss_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pressure [MPa]</th>\n",
       "      <th>mass_flux [kg/m2-s]</th>\n",
       "      <th>D_e [mm]</th>\n",
       "      <th>D_h [mm]</th>\n",
       "      <th>length [mm]</th>\n",
       "      <th>chf_exp [MW/m2]</th>\n",
       "      <th>x_e_out [-]</th>\n",
       "      <th>author</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.287262</td>\n",
       "      <td>0.526524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200611</td>\n",
       "      <td>-0.226988</td>\n",
       "      <td>0.134758</td>\n",
       "      <td>1.742209</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.142186</td>\n",
       "      <td>0.559467</td>\n",
       "      <td>0.146413</td>\n",
       "      <td>0.300649</td>\n",
       "      <td>1.269136</td>\n",
       "      <td>-0.413280</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523898</td>\n",
       "      <td>-0.276973</td>\n",
       "      <td>0.099124</td>\n",
       "      <td>-0.186221</td>\n",
       "      <td>-0.174684</td>\n",
       "      <td>-0.626153</td>\n",
       "      <td>0.332698</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.523898</td>\n",
       "      <td>0.494708</td>\n",
       "      <td>-0.404782</td>\n",
       "      <td>0.591356</td>\n",
       "      <td>1.258083</td>\n",
       "      <td>-0.245698</td>\n",
       "      <td>-0.277196</td>\n",
       "      <td>Beus</td>\n",
       "      <td>annulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.523898</td>\n",
       "      <td>-1.692217</td>\n",
       "      <td>0.677829</td>\n",
       "      <td>0.231938</td>\n",
       "      <td>-0.174684</td>\n",
       "      <td>-0.389667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tube</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pressure [MPa]  mass_flux [kg/m2-s]  D_e [mm]  D_h [mm]  length [mm]  \\\n",
       "id                                                                         \n",
       "0        -0.287262             0.526524       NaN  0.200611    -0.226988   \n",
       "1              NaN             1.142186  0.559467  0.146413     0.300649   \n",
       "2         0.523898            -0.276973  0.099124 -0.186221    -0.174684   \n",
       "3         0.523898             0.494708 -0.404782  0.591356     1.258083   \n",
       "4         0.523898            -1.692217  0.677829  0.231938    -0.174684   \n",
       "\n",
       "    chf_exp [MW/m2]  x_e_out [-]    author geometry  \n",
       "id                                                   \n",
       "0          0.134758     1.742209  Thompson     tube  \n",
       "1          1.269136    -0.413280  Thompson     tube  \n",
       "2         -0.626153     0.332698  Thompson      NaN  \n",
       "3         -0.245698    -0.277196      Beus  annulus  \n",
       "4         -0.389667          NaN       NaN     tube  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform df_train by taking log of positive columns and normalizing\n",
    "df_train_log = df_train.select_dtypes(include=[float]).copy().drop(columns=[\"x_e_out [-]\"])\n",
    "df_train_log[df_train_log == 0] += 1e-6\n",
    "df_train_log = np.log(df_train_log)\n",
    "\n",
    "# add back x_e_out\n",
    "df_train_log[\"x_e_out [-]\"] = df_train[\"x_e_out [-]\"]\n",
    "\n",
    "means = df_train_log.mean()\n",
    "stds = df_train_log.std()\n",
    "df_train_log = (df_train_log - means) / stds\n",
    "\n",
    "df_train_log = pd.concat([df_train_log, df_train.select_dtypes(include=[object])], axis=1)\n",
    "df_train_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"author\", \"geometry\"]\n",
    "p_mask = 0.2\n",
    "ds_train = MaskingDataset(df_train_log, p_mask=p_mask, categorical_cols=categorical_cols)\n",
    "ds_dev = MaskingDataset(df_dev, p_mask=p_mask, categorical_cols=categorical_cols)\n",
    "ds_test = MaskingDataset(df_test, p_mask=p_mask, categorical_cols=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 1.7881087514802472\n",
      "Epoch 1 loss: 1.7330585090652693\n",
      "Epoch 2 loss: 1.7305762412906176\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_165590/3303292386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.16/envs/kaggle3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_165590/1666432965.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mslice_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_categorical\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_is_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_categorical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.16/envs/kaggle3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_165590/1666432965.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.16/envs/kaggle3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.16/envs/kaggle3.7/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(ds_train, batch_size=32, shuffle=True)\n",
    "\n",
    "x_size = ds_train[0][0].shape[0]\n",
    "cat_slices = [[7,17],[17,20]]\n",
    "\n",
    "inner_model = FFModel(x_size, 128, x_size)\n",
    "model = MixedContCatModel(inner_model, cat_slices, x_size)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "ccloss = ContCatLoss(cat_slices, x_size)\n",
    "criterion = MixedContCatLoss(ccloss, 0.2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch} loss: {running_loss / len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~torch.tensor([1,torch.nan,3]).isnan() * torch.tensor([1,2,3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
